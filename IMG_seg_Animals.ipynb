{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "862OBlAdLeXt"
      },
      "source": [
        "# CIL Road Segmentation\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WpXtlRMfuuOr"
      },
      "source": [
        "## preparation\n",
        "You need to download the oxford-iiit pet dataset https://www.robots.ox.ac.uk/~vgg/data/pets/."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use data from drive, when using colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvIjL9CGOFjx"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b-aCUquOUVC",
        "outputId": "aabb7375-6d5a-4886-e44b-b2e1ac588c0b"
      },
      "outputs": [],
      "source": [
        "#drive.mount(\"/content/gdrive\")\n",
        "#cd gdrive/My Drive/img_seg_animals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd img_seg_animals"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ohkRvDuQLNmZ"
      },
      "source": [
        "## explore data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGkO5EU_8Suz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5xn4uEW8b6e",
        "outputId": "48a5f397-5157-4023-c37b-a1c6f78df692"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"annotations/list.txt\",\n",
        "    delimiter=\" \",\n",
        "    skiprows=6,\n",
        "    header=None,\n",
        "    names=[\"stem\", \"class_id\", \"species\", \"breed\"]\n",
        ")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw0NrkPm8b2W",
        "outputId": "6ce2b75f-42ab-4dff-8d44-ec0155485bb6"
      },
      "outputs": [],
      "source": [
        "df[\"class_name\"] = df.stem.map(lambda x: x.split(\"_\")[0])\n",
        "df[\"image_path\"] = df.stem.map(lambda x: f\"images/{x}.jpg\")\n",
        "df[\"annotations\"] = df.stem.map(lambda x: f\"annotations/trimaps/trimaps/{x}.png\")\n",
        "df.tail()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xpFrL9-A9l4J"
      },
      "source": [
        "The species 1 stands for cats, and 2 for dogs, class_id stands for the subtype.\n",
        "\n",
        "Now we want to look at the distribution of classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfu8PDE48bsD",
        "outputId": "07499d3f-b77d-4579-872c-079f796bbda3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.histplot(df.class_id)\n",
        "plt.title(\"class id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNAMH7ug_ElR",
        "outputId": "bfe7c783-e155-4cd6-d70a-9b10118378d0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plot = sns.histplot(df.class_name)\n",
        "plt.setp(plot.get_xticklabels(), rotation=90)\n",
        "\n",
        "plt.title(\"Class name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLG1FP06BGMz",
        "outputId": "9c41dba5-9709-428b-8a29-fb50167ef3df"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plot = sns.histplot(df.species, discrete=True)\n",
        "plt.title(\"species\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2DY_-I2jBjBT"
      },
      "source": [
        "Looks like there are more dogs than cats, but the breeds, classes etc. are balanced enough for our purpose(nothing likea breed that only has 2 images, which we would need to remove).\n",
        "\n",
        "Now leets look at the images themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNwLzU7wCsPX",
        "outputId": "071fbb41-4a47-4e65-c2d1-064918d5b60b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,2, figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    img = Image.open(df.image_path[i])\n",
        "    annot = Image.open(df.annotations[i])\n",
        "    ax[i, 0].imshow(img)\n",
        "    ax[i, 1].imshow(annot)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t08D73HV4CAd",
        "outputId": "354c9f81-0195-4dff-da12-a08f720dd606"
      },
      "outputs": [],
      "source": [
        "set(Image.open(df.annotations[i]).getdata())#inside outside border"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8wgWE_atFj3V"
      },
      "source": [
        "The images have different sizes, what makes this problem harder, the annotations don't seem to be too hard to learn, as there are not that many wery thin features."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "--seJcsDLTRG"
      },
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGXYb718GUE2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-ZlQ7LkGUjc"
      },
      "outputs": [],
      "source": [
        "class animal_data(Dataset):\n",
        "    def __init__(self, df, tfm=None):\n",
        "        self.df = df\n",
        "        self.tfm = tfm #transformations\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.df.image_path.iloc[i]).convert('RGB')\n",
        "        mask = Image.open(self.df.annotations.iloc[i])\n",
        "        img = np.asarray(img)\n",
        "        mask = np.where(np.asarray(mask)!=2, 1, 0)\n",
        "        if self.tfm:\n",
        "            augmented = self.tfm(image=img, mask=mask)\n",
        "            img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
        "        #img = (img.float() - 128)/300 # rescale values\n",
        "        img = (img.to(torch.float)-128)/300\n",
        "        #print(torch.min(img))\n",
        "        return img, mask#  BECAUSE THE LABELS ARE 1,2,3, and I dont really care about the difference between 2 and 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVBiXN7JHi4z"
      },
      "outputs": [],
      "source": [
        "transformations = albumentations.Compose([\n",
        "    albumentations.HorizontalFlip(p=0.4), \n",
        "    albumentations.VerticalFlip(p=0.3),\n",
        "    albumentations.RandomScale(),\n",
        "    albumentations.Rotate(border_mode=cv2.BORDER_CONSTANT, mask_value=0),\n",
        "    albumentations.RandomBrightnessContrast(p=0.3),\n",
        "    albumentations.SmallestMaxSize(256), #spmewhat controll img size\n",
        "    #albumentations.augmentations.crops.transforms.RandomCropFromBorders(p=.4),#somehow not working\n",
        "    #albumentations.Normalize(),\n",
        "    albumentations.RandomCrop(256, 256),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transformations = albumentations.Compose([\n",
        "    albumentations.SmallestMaxSize(256),\n",
        "    #albumentations.Normalize(),\n",
        "    albumentations.RandomCrop(256, 256),# could do CenterCrop for consistency, but i like this one more\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# missing : Mixup, Cutmix, RandAugment, Random erazing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHBRXnG0Hi2a"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(5)\n",
        "train_idx, val_idx = next(iter(skf.split(df, df.class_id)))\n",
        "train_df = df.iloc[train_idx]\n",
        "val_df = df.iloc[val_idx]\n",
        "\n",
        "train_ds = animal_data(train_df, tfm=transformations)\n",
        "val_ds = animal_data(val_df, tfm=val_transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjGWAnI78fYi"
      },
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAaHcBifHiza",
        "outputId": "ed60dd30-c713-454c-fb69-00ceb314fd88"
      },
      "outputs": [],
      "source": [
        "\n",
        "for _ in range(4):\n",
        "    #img, mask = train_ds[0]\n",
        "    img, mask = next(iter(train_dataloader))\n",
        "    img, mask = img[0], mask[0] \n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img.numpy().transpose(1,2,0))\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask)\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "    #print(torch.min(img))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "db0IbdeGLY4P"
      },
      "source": [
        "## models to explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-7--SUJqY5U",
        "outputId": "01e78564-5271-43f8-893c-36df88afd771"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch\n",
        "resnet = resnet50(weights = ResNet50_Weights.IMAGENET1K_V2)\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initial model for comparison\n",
        "class CNN_might_help(torch.nn.Module):# just trash to see if everything works\n",
        "    def __init__(self):\n",
        "        super(CNN_might_help, self).__init__()\n",
        "\n",
        "        self.batchsize = batch_size#batch_size\n",
        "        self.num_classes = 2\n",
        "\n",
        "        self.backbone = torch.nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2# batch_size * 512 * size/8\n",
        "            #resnet.layer3,# og size / 16\n",
        "        )\n",
        "        self.backbone.requires_grad_ = True#False in the beginning\n",
        "        \n",
        "        self.cnn_pt2 = torch.nn.Sequential(# less compression than using more resnet layers\n",
        "            torch.nn.Conv2d(512,256,kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),#batch_size * 256 * 100 *100\n",
        "            torch.nn.Conv2d(256,128,kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(128,32,kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(32, self.num_classes if 2 !=  self.num_classes else 1 ,kernel_size = 3, padding = 1),\n",
        "        )\n",
        "        #self.cnn_pt2.requires_grad_ = True\n",
        "\n",
        "        # get back dimensions\n",
        "        self.upsampler = torch.nn.Upsample(scale_factor=8, mode=\"bilinear\")\n",
        "        # I am not a fan of upsampling, but the model is already slow, so making it bigger with a u-net like achitecture is too expensive\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.cnn_pt2(x)\n",
        "        x = self.upsampler(x)\n",
        "        x= torch.nn.functional.sigmoid(x)   \n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "viSNAXiDpF0x"
      },
      "source": [
        "### SCG Net\n",
        "resnet backbone GNN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q422EKsABBtx"
      },
      "source": [
        "The model has been inspired by https://arxiv.org/pdf/2009.01599.pdf but has been changed/adjusted to the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQYJSbIVqkWc",
        "outputId": "48be5e8b-02ee-42ba-b594-2caafc100703"
      },
      "outputs": [],
      "source": [
        "#pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMT_v1luPJh0"
      },
      "outputs": [],
      "source": [
        "class mini_Scg_Net(torch.nn.Module):# just trash to see if everything works\n",
        "    def __init__(self):\n",
        "        super(mini_Scg_Net, self).__init__()\n",
        "        self.batchsize = batch_size#batch_size\n",
        "        \n",
        "        self.backbone = torch.nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2# batch_size * 512 * size/8\n",
        "            #resnet.layer3,# og size / 16\n",
        "        )\n",
        "        self.backbone.requires_grad_ = True#False in the beginning\n",
        "        num_classes = 2\n",
        "        self.out_size = num_classes if 2 !=  num_classes else 1 \n",
        "\n",
        "        self.cnn_extension = torch.nn.Sequential(# less compression than using more resnet layers\n",
        "            torch.nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 256, kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(256, 128, kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU()#batch_size * 256 * 100 *100\n",
        "        )\n",
        "        # endoder\n",
        "        self.encoder_mean = torch.nn.Conv2d(128, self.out_size, kernel_size = 3, padding = 1)# could also do only 1 output but I think that might be bad\n",
        "        self.encoder_var = torch.nn.Conv2d(128, self.out_size, kernel_size = 1, padding = 0)\n",
        "        # I am not a fan of the variational part here\n",
        "\n",
        "        # decoder\n",
        "        # no\n",
        "\n",
        "        # GNN\n",
        "        #self.GNN = torch.nn.Sequential(\n",
        "        self.conv1 = GCNConv(self.out_size, self.out_size)\n",
        "        self.conv2 = GCNConv(self.out_size, self.out_size)\n",
        "        #)\n",
        "\n",
        "        # get back dimensions\n",
        "        self.upsampler = torch.nn.Upsample(scale_factor=8, mode=\"bilinear\")\n",
        "        # I am not a fan of upsampling, but the model is already slow, so making it bigger with a u-net like achitecture is too expensive\n",
        "\n",
        "        self.reduzed_size = int(self.batchsize*(256/8)**2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.cnn_extension(x)#F\n",
        "        \n",
        "        # the GNN does not seem to allow batch sizes\n",
        "        # only one adj. matrix is allowed\n",
        "        # VAE\n",
        "        \n",
        "        M = self.encoder_mean(x).reshape((self.out_size, -1))# flatten img\n",
        "        #sigma = torch.exp(self.encoder_var(x).reshape((self.out_size, -1)))\n",
        "        \n",
        "        x = M #+ sigma * torch.randn((self.out_size, self.reduzed_size)).cuda()# add or remove .cuda() depending on use\n",
        "        #Z_res = M *(1 - log_sigma)\n",
        "        x = torch.permute(x, (1, 0))# put channels at the end\n",
        "        A = torch.nn.functional.relu(torch.inner(x, x)).to_sparse()\n",
        "        # this part is horrible but the library requires trash input\n",
        "        edge_idx, weights = torch_geometric.utils.to_edge_index(A)   \n",
        "        \n",
        "        #Z = Z.unsqueeze(-1)\n",
        "        #Z\n",
        "        # cnn needs channels, dims, but gnn needs dims, channels\n",
        "\n",
        "        # GNN\n",
        "        x = self.conv1(x, edge_idx, edge_weight = weights)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.conv2(x, edge_idx, edge_weight = weights)\n",
        "        #x = torch.nn.functional.softmax(x)# useless?\n",
        "        \n",
        "        x = torch.permute(x, (1, 0)) # not sure if needed or if reshape would do the right thing\n",
        "        x = x.reshape((1, self.out_size, 32, 32))\n",
        "        x = self.upsampler(x)\n",
        "        x = torch.nn.functional.sigmoid(x)       \n",
        "        return x, M, A#, sigma"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This might also be influenced by sub-optimal kl-divergence implementations, but the vae version did not work at all for me. The \"normal\" ae marked roughly the correct part of the image but was not very good."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### U-net\n",
        "https://github.com/milesial/Pytorch-UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (DoubleConv(n_channels, 64))\n",
        "        self.down1 = (Down(64, 128))\n",
        "        self.down2 = (Down(128, 256))\n",
        "        self.down3 = (Down(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Down(512, 1024 // factor))\n",
        "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Up(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        x = torch.nn.functional.sigmoid(x) \n",
        "        return x\n",
        "\n",
        "    def use_checkpointing(self):#unused\n",
        "        self.inc = torch.utils.checkpoint(self.inc)\n",
        "        self.down1 = torch.utils.checkpoint(self.down1)\n",
        "        self.down2 = torch.utils.checkpoint(self.down2)\n",
        "        self.down3 = torch.utils.checkpoint(self.down3)\n",
        "        self.down4 = torch.utils.checkpoint(self.down4)\n",
        "        self.up1 = torch.utils.checkpoint(self.up1)\n",
        "        self.up2 = torch.utils.checkpoint(self.up2)\n",
        "        self.up3 = torch.utils.checkpoint(self.up3)\n",
        "        self.up4 = torch.utils.checkpoint(self.up4)\n",
        "        self.outc = torch.utils.checkpoint(self.outc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRaAkwtwRt4m"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "test123 = UNet(n_channels = 3, n_classes = 2)#mini_Scg_Net()#CNN_might_help()#mini_Scg_Net()\n",
        "test123.to(device)\n",
        "data_iter = iter(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXwp4Vj-GmSH"
      },
      "outputs": [],
      "source": [
        "X, label = next(data_iter)\n",
        "#print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiwzvVtxRipN"
      },
      "outputs": [],
      "source": [
        "#output, M, A, sigma = test123(X.to(device))\n",
        "output = test123(X.to(device))\n",
        "#output = test123(X.to(device))\n",
        "\n",
        "output.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bp_Xnl9_OcDY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFZxBvtDk7qB",
        "outputId": "4eb90369-e19c-40be-8c16-ed768b7e4adc"
      },
      "outputs": [],
      "source": [
        "#pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BApiPmg1y3oa"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import LinearLR\n",
        "from tqdm import tqdm  # tqdm.notebook\n",
        "import math\n",
        "#from torchmetrics import Dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UQZ9h9uecfN"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqhr-sdELSol"
      },
      "outputs": [],
      "source": [
        "#curr_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq-w1HJBOsxm",
        "outputId": "515cd35c-f20d-41cc-cdfa-fa4e81a9e4f8"
      },
      "outputs": [],
      "source": [
        "#torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "curr_model = UNet(n_channels = 3, n_classes = 1)#mini_Scg_Net()#mini_Scg_Net()#CNN_might_help()#\n",
        "curr_model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#torch.autograd.detect_anomaly(True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "choose which model you want to load, if you have a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVvvFdSAEX5W",
        "outputId": "abd15e15-10a8-4fa8-a03f-62583a79f36c"
      },
      "outputs": [],
      "source": [
        "#curr_model.load_state_dict(torch.load(\"SCG-net/model_weights.pth\", map_location=torch.device(device)),strict=False)\n",
        "#curr_model.load_state_dict(torch.load(\"CNN/model_weights.pth\", map_location=torch.device(device)))\n",
        "#curr_model.load_state_dict(torch.load(\"unet/model_weights.pth\", map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB7scrF7yxON"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, curr_model.parameters()), #curr_model.parameters(), #filter(lambda p: p.requires_grad, curr_model.parameters())\n",
        "                       lr=2e-3, weight_decay=1e-8)\n",
        "scheduler = LinearLR(start_factor = 2e-3, \n",
        "                     end_factor = 2e-5,\n",
        "                     last_epoch = -1,\n",
        "                     total_iters = num_epochs,\n",
        "                     optimizer = optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(torch.nn.Module):# binary\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #inputs = torch.nn.functional.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten \n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        \n",
        "        return 1 - dice\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-xhi_cGOaUm"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, device, num_epochs=100):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    #loss_func = Dice(num_classes = 3).to(device)\n",
        "    loss_func = DiceLoss()\n",
        "    #loss_func = torch.nn.BCELoss()\n",
        "    const = (32*32)**2\n",
        "    epsilon = 1e-7\n",
        "    smaller_epsilon = 1e-20\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        iteration_loss = 0.\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Reset the optimizer.\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            #outputs, M,  A= model(X)#, sigma \n",
        "            outputs = model(X)\n",
        "\n",
        "            #print(\"X input: \",X.shape)\n",
        "            #print(\"y: \",y.shape)\n",
        "            #print(\"prediction: \",outputs.shape)\n",
        "\n",
        "            # Compute the loss and do the backward pass.\n",
        "            loss_base = loss_func(outputs, y)# .flatten()   , .to(torch.float32)\n",
        "            #loss_KL = torch.div(torch.sum(torch.add(torch.pow(log_sigma, 2), 1) - torch.pow(M, 2) - torch.pow(torch.exp(log_sigma), 2)),\n",
        "            #                       -6144)# this version seems to be wrong(copied formula from paper) and gives you negative kl divs which is not allowed\n",
        "\n",
        "            #loss_KL = torch.div(torch.sum(torch.pow(M, 2) + torch.pow(sigma, 2) - torch.log(torch.pow(sigma, 2)+smaller_epsilon) - 1 ),\n",
        "            #                       2048)#32*32*num_classes(1 if 2)*2#formula according to PAI script\n",
        "\n",
        "            #A = A.to_dense()\n",
        "            #gamma = torch.sqrt(1 + torch.divide(1024, #32*32\n",
        "            #                                    torch.sum(torch.diag(A) + epsilon)))\n",
        "            #loss_dl = -(gamma/const)*(torch.sum(torch.log(torch.clamp(torch.abs(torch.diagonal(A)), \n",
        "            #                                                          min = 0., max = 1.)+ epsilon)))\n",
        "            #print(\"loss_base: \", loss_base, \"\\nloss_KL: \", loss_KL, \"\\nloss_dl: \", loss_dl)\n",
        "            \n",
        "            loss = loss_base #+ loss_dl #+ loss_KL#  I think I need weighting\n",
        "            loss.backward()\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
        "            # was having problems with nans\n",
        "\n",
        "            optimizer.step()\n",
        "            iteration_loss += loss.item()\n",
        "        \n",
        "        print(f'Epoch {epoch}/{num_epochs}, ' ,\n",
        "              f'Train Loss: {iteration_loss / len(data_loader):.4f}, ',\n",
        "              )\n",
        "        \n",
        "        if math.isnan(iteration_loss):# something broke again\n",
        "            from winsound import Beep\n",
        "            Beep(300, 5000)\n",
        "            break\n",
        "\n",
        "        if(epoch %5 == 0):\n",
        "            print(\"save the weights\")\n",
        "            #torch.save(model.state_dict(), \"CNN/model_weights.pth\")\n",
        "            #torch.save(model.state_dict(), \"SCG-net/model_weights.pth\")\n",
        "            #torch.save(model.state_dict(), \"unet/model_weights.pth\")\n",
        "        scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "f41b511056984c869567660cc79def51",
            "3a67330e44ac43a8885867ac4239bbef",
            "20b6e62e546f46258edd7d60b3fa33c8",
            "279a42858abb498ea2f6caca61ada00f",
            "2395daa9c2a8428fb0a0623ebbcc460e",
            "89326735f8364225b7be88a6e4cf3eca",
            "5fbb251a60dc4c6a850fb702fcb323f4",
            "134c7486faef452f9ddd700220c4c194",
            "11c658e2d83f4c268bf83935c2ff25d5",
            "c2643eaa5aca4d0aac82c430837242fe",
            "771b78153423479fa71e194b680700c0",
            "2cf7cc08d8a34dc6b18d851f53c6f256",
            "ca1e56a3a6544cd78a362852b2a583b2",
            "8b69d2cfbe194a95a87b3fada330d293",
            "00a8e14715734999ab3cd626648fa02a",
            "c0d8e34735cc409e91b4698573cbb083",
            "00a9e2e04d1d4383a9cccaaf8de8d992",
            "b499d71e9ad74397842c67e2b1c5b062",
            "12ce287fa5934b40821673d17eec1c6b",
            "465834653ea14d43a52746e2f533fc0d",
            "452ae39f5ff84e24a78c370de7255828",
            "4b5a50753f914af587865ba9e880df72"
          ]
        },
        "id": "Xw66E1DWOfYF",
        "outputId": "706662ab-e74b-467b-d4e7-39c5da301f29"
      },
      "outputs": [],
      "source": [
        "train(curr_model, train_dataloader, device, num_epochs = num_epochs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from winsound import Beep\n",
        "Beep(300, 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fpDF-qJiaW6"
      },
      "outputs": [],
      "source": [
        "#from google.colab import output\n",
        "#output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkaKGqOp_t8R"
      },
      "outputs": [],
      "source": [
        "#torch.save(curr_model.state_dict(), \"SCG-net/model_weights.pth\")\n",
        "#torch.save(curr_model.state_dict(), \"CNN/model_weights.pth\")\n",
        "torch.save(curr_model.state_dict(), \"unet/model_weights.pth\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "USOjXiS5wIGE"
      },
      "source": [
        " ## Test\n",
        " Now we test the performance of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMBoeWTdw8j_"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import F1Score, Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM1KBFy1xL72"
      },
      "outputs": [],
      "source": [
        "curr_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f01CmNFQOabq"
      },
      "outputs": [],
      "source": [
        "f1 = F1Score(task=\"binary\",\n",
        "             #num_classes = 3\n",
        "             )\n",
        "acc = Accuracy(task=\"binary\"#, num_classes=3\n",
        "               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KP7xBATwHlv"
      },
      "outputs": [],
      "source": [
        "f_list = []\n",
        "acc_list = []\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    for X, y in tqdm(test_dataloader):\n",
        "        X, y = X.to(device), y.squeeze()#.to(device)\n",
        "        outputs= curr_model(X)#, _, _, _ \n",
        "        #outputs = torch.permute(outputs.squeeze(), (1,2,0))\n",
        "        #print(\"X input: \", X.shape)\n",
        "        #print(\"y: \", y.shape)\n",
        "        #print(\"prediction: \", outputs.shape)\n",
        "        outputs = outputs.squeeze().cpu()\n",
        "        f_sc = f1(outputs, y)\n",
        "        f_list.append(f_sc)\n",
        "        \n",
        "        acc_sc = acc(outputs, y)\n",
        "        acc_list.append(acc_sc)\n",
        "        i+=1\n",
        "        if i%100==0:\n",
        "            print(\"accuracy: \", sum(acc_list)/len(test_dataloader))\n",
        "            print(\"f1-score: \", sum(f_list)/len(test_dataloader))\n",
        "#f_list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VRGmxp0OfhG",
        "outputId": "9c93126e-4271-422b-d759-652ac16c42fc"
      },
      "outputs": [],
      "source": [
        "print(\"accuracy: \", sum(acc_list)/len(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkL_0N7Y6JFN"
      },
      "outputs": [],
      "source": [
        "print(\"f1-score: \", sum(f_list)/len(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nTSwC9e9kdU"
      },
      "outputs": [],
      "source": [
        "#curr_model.to(\"cpu\")\n",
        "fig, ax = plt.subplots(1,4, figsize=(20,5))\n",
        "\n",
        "img, mask = next(iter(test_dataloader))\n",
        "img_plot = img.squeeze()\n",
        "\n",
        "og_color = ax[0]#plt.subplot(1,4,1)\n",
        "og_color.imshow(np.round(img_plot.numpy().transpose(1,2,0)*300+128).astype(int))\n",
        "og_color.title.set_text(\"original(colors restored)\")\n",
        "\n",
        "\n",
        "og_permuted = ax[1]#plt.subplot(1,4,2)\n",
        "og_permuted.imshow(img_plot.numpy().transpose(1,2,0))\n",
        "og_permuted.title.set_text(\"original(permuted)\")\n",
        "\n",
        "plt.xticks([]); plt.yticks([])\n",
        "mask = mask.squeeze()\n",
        "\n",
        "sol = ax[2]#plt.subplot(1,4,3)\n",
        "sol.imshow(mask.numpy())\n",
        "sol.title.set_text(\"ground truth\")\n",
        "\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "outputs, _, _= curr_model(img.to(device))#, _, _, _ \n",
        "#outputs = curr_model(img.to(device))\n",
        "\n",
        "outputs = torch.where((outputs).squeeze() >0.5, 1, 0)  \n",
        "\n",
        "# for multi class\n",
        "#outputs = torch.permute(outputs.squeeze(), (1,2,0))\n",
        "#outputs = torch.max(outputs.detach(), -1)\n",
        "#print(outputs)\n",
        "\n",
        "pred = ax[3]#plt.subplot(1,4,4)\n",
        "pred.imshow(outputs.cpu())\n",
        "pred.title.set_text(\"prediction\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WpXtlRMfuuOr",
        "ohkRvDuQLNmZ",
        "--seJcsDLTRG"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a8e14715734999ab3cd626648fa02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452ae39f5ff84e24a78c370de7255828",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4b5a50753f914af587865ba9e880df72",
            "value": " 801/5879 [00:26&lt;09:11,  9.21it/s]"
          }
        },
        "00a9e2e04d1d4383a9cccaaf8de8d992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c658e2d83f4c268bf83935c2ff25d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12ce287fa5934b40821673d17eec1c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134c7486faef452f9ddd700220c4c194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b6e62e546f46258edd7d60b3fa33c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134c7486faef452f9ddd700220c4c194",
            "max": 5879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11c658e2d83f4c268bf83935c2ff25d5",
            "value": 5879
          }
        },
        "2395daa9c2a8428fb0a0623ebbcc460e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279a42858abb498ea2f6caca61ada00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2643eaa5aca4d0aac82c430837242fe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_771b78153423479fa71e194b680700c0",
            "value": " 5879/5879 [2:28:00&lt;00:00,  1.77s/it]"
          }
        },
        "2cf7cc08d8a34dc6b18d851f53c6f256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca1e56a3a6544cd78a362852b2a583b2",
              "IPY_MODEL_8b69d2cfbe194a95a87b3fada330d293",
              "IPY_MODEL_00a8e14715734999ab3cd626648fa02a"
            ],
            "layout": "IPY_MODEL_c0d8e34735cc409e91b4698573cbb083"
          }
        },
        "3a67330e44ac43a8885867ac4239bbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89326735f8364225b7be88a6e4cf3eca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5fbb251a60dc4c6a850fb702fcb323f4",
            "value": "100%"
          }
        },
        "452ae39f5ff84e24a78c370de7255828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465834653ea14d43a52746e2f533fc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b5a50753f914af587865ba9e880df72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fbb251a60dc4c6a850fb702fcb323f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771b78153423479fa71e194b680700c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89326735f8364225b7be88a6e4cf3eca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b69d2cfbe194a95a87b3fada330d293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ce287fa5934b40821673d17eec1c6b",
            "max": 5879,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_465834653ea14d43a52746e2f533fc0d",
            "value": 801
          }
        },
        "b499d71e9ad74397842c67e2b1c5b062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d8e34735cc409e91b4698573cbb083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2643eaa5aca4d0aac82c430837242fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1e56a3a6544cd78a362852b2a583b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a9e2e04d1d4383a9cccaaf8de8d992",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b499d71e9ad74397842c67e2b1c5b062",
            "value": " 14%"
          }
        },
        "f41b511056984c869567660cc79def51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a67330e44ac43a8885867ac4239bbef",
              "IPY_MODEL_20b6e62e546f46258edd7d60b3fa33c8",
              "IPY_MODEL_279a42858abb498ea2f6caca61ada00f"
            ],
            "layout": "IPY_MODEL_2395daa9c2a8428fb0a0623ebbcc460e"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
